{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pytry3g.com/entry/2018/04/27/225711\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "train_x, test_x, train_t, test_t = train_test_split(data, target, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.layer = nn.Linear(4,3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "model = NN()\n",
    "optimizer = O.Adam(model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0868, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0838, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1302, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1620, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1150, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2436, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0983, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1285, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0866, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0897, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1909, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0926, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1379, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2042, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0522, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1935, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0995, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0874, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1400, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1230, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0812, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1588, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0994, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0769, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0600, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1591, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1127, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0976, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0800, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1433, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1413, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0602, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1188, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0899, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0834, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0909, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0796, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0971, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1345, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1290, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1599, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0647, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0504, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0665, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0930, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1309, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0714, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0914, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1598, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1137, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0955, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1367, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1552, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0934, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0885, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0956, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0625, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1179, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0609, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0895, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0575, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(40):\n",
    "    train_x , train_t = shuffle(train_x, train_t)\n",
    "    for i in range(0, len(train_x), 30):\n",
    "        x=torch.tensor(train_x[i:i+30], dtype=torch.float)\n",
    "        t=torch.tensor(train_t[i:i+30], dtype=torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x)\n",
    "        loss = criterion(y, t)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor(test_x, dtype=torch.float, requires_grad=False)\n",
    "result = model(tensor)\n",
    "#   モデルがテストデータを予測した結果\n",
    "predicted = torch.max(result, 1)[1]\n",
    "# 正解データ\n",
    "label = torch.tensor(test_t, dtype=torch.long)\n",
    "print(\"Accuracy: {}\".format((predicted == label).sum().item() / len(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor.sum())\n",
    "# tensor(6)\n",
    "print(tensor.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2, 2, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.9987, 9.8020, 3.6776, 4.5567, 9.0946, 2.7622, 9.8798, 3.0515, 3.0394,\n",
       "         2.8896, 9.7733, 9.8841, 5.1822, 2.9902, 4.8745],\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([0, 0, 2, 2, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(result,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1694, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
